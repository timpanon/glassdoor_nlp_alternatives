{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScrape reviews from glassdoor using given links \\nSaves individual company reviews to csv file\\nMethod to combine all csvs into one dataframe included \\n'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scrape reviews from glassdoor using given links \n",
    "Saves individual company reviews to csv file\n",
    "Method to combine all csvs into one dataframe included \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes in a list of csv files using glob \n",
    "Output: dataframe combining all csvs vertically (axis=0)\n",
    "Assumes all csvs have same column names \n",
    "\"\"\"\n",
    "def files_to_df(glob_csv):\n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    for file in glob_csv:\n",
    "        df = pd.read_csv(file)\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "        final_df = pd.concat([final_df, df])\n",
    "        \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfiles = glob.glob('reviews/top_50_smb/' + '*.csv')\n",
    "top_50_smb_reviews = files_to_df(csvfiles)\n",
    "\n",
    "# for file in csvfiles:\n",
    "#     df = pd.read_csv(file)\n",
    "#     df = df.drop(df.columns[0], axis=1)\n",
    "#     top_50_smb_reviews = pd.concat([top_50_smb_reviews, df])\n",
    "\n",
    "top_50_smb_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfiles = glob.glob('reviews/top_50_large/' + '*.csv')\n",
    "top_50_large_reviews =  files_to_df(csvfiles)\n",
    "top_50_large_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('links_top_50_smb.pickle','rb') as f:\n",
    "    links_top_50_smb = pickle.load(f)\n",
    "    \n",
    "with open('links_top_50_large.pickle','rb') as f:\n",
    "    links_top_50_large = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.glassdoor.com/Reviews/Lawrence-Livermore-National-Laboratory-Reviews-E35235.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Zscaler-Reviews-E359434.htm',\n",
       " 'https://www.glassdoor.com/Reviews/In-N-Out-Burger-Reviews-E14276.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Tanium-Reviews-E952409.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Red-Hat-Reviews-E8868.htm',\n",
       " 'https://www.glassdoor.com/Reviews/SAP-Reviews-E10471.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Zendesk-Reviews-E360923.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Silicon-Valley-Bank-Reviews-E107161.htm',\n",
       " 'https://www.glassdoor.com/Reviews/AppFolio-Reviews-E225531.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Merck-Reviews-E438.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Meta-Reviews-E40772.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Houston-Methodist-Reviews-E4460.htm',\n",
       " 'https://www.glassdoor.com/Reviews/St-Jude-Children-s-Research-Hospital-Reviews-E28315.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Southern-California-Edison-Reviews-E15209.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Keller-Williams-Reviews-E114145.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Boston-Scientific-Reviews-E2187.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Curriculum-Associates-Reviews-E334270.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Zillow-Reviews-E40802.htm',\n",
       " 'https://www.glassdoor.com/Reviews/eBay-Reviews-E7853.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Apple-Reviews-E1138.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Texas-Instruments-Reviews-E651.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Momentum-Solar-Reviews-E1387632.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Fidelity-Investments-Reviews-E2786.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Qualtrics-Reviews-E323717.htm',\n",
       " 'https://www.glassdoor.com/Reviews/First-Republic-Bank-Reviews-E859.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Robins-and-Morton-Reviews-E339105.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Slalom-Reviews-E31102.htm',\n",
       " 'https://www.glassdoor.com/Reviews/AMD-Reviews-E15.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Coldwell-Banker-Reviews-E13952.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Viasat-Reviews-E5500.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Atlassian-Reviews-E115699.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Forrester-Reviews-E6443.htm',\n",
       " 'https://www.glassdoor.com/Reviews/CDW-Reviews-E2347.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Databricks-Reviews-E954734.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Visa-Inc-Reviews-E3035.htm',\n",
       " 'https://www.glassdoor.com/Reviews/SailPoint-Technologies-Reviews-E449696.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Capital-One-Reviews-E3736.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Roche-Reviews-E3480.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Johnson-and-Johnson-Reviews-E364.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Workday-Reviews-E197851.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Randstad-Sourceright-Reviews-E494861.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Est√©e-Lauder-Companies-Reviews-E2785.htm',\n",
       " 'https://www.glassdoor.com/Reviews/NIH-Reviews-E11709.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Wegmans-Food-Markets-Reviews-E3042.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Cisco-Systems-Reviews-E1425.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Mars-Reviews-E2886.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Medtronic-Reviews-E436.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Vans-Reviews-E881.htm',\n",
       " 'https://www.glassdoor.com/Reviews/VMware-Reviews-E12830.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Mayo-Clinic-Reviews-E19884.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Qualcomm-Reviews-E640.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Madewell-Reviews-E426474.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Exact-Sciences-Reviews-E12829.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Scheels-Reviews-E32500.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Procore-Technologies-Reviews-E691343.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Intel-Corporation-Reviews-E1519.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Costco-Wholesale-Reviews-E2590.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Pfizer-Reviews-E525.htm',\n",
       " 'https://www.glassdoor.com/Reviews/REI-Reviews-E7319.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Cincinnati-Children-s-Hospital-Reviews-E19251.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Universal-Studios-Reviews-E4200.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Malouf-Companies-Reviews-E1069181.htm',\n",
       " 'https://www.glassdoor.com/Reviews/RE-MAX-Reviews-E3867.htm',\n",
       " 'https://www.glassdoor.com/Reviews/Zoom-Video-Communications-Reviews-E924644.htm']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_top_50_large[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add a print for each company to keep track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-16\n",
      "2014-10-08\n",
      "2014-12-15\n",
      "2014-12-25\n",
      "2014-12-31\n",
      "2014-12-19\n",
      "2014-12-09\n",
      "2014-12-09\n",
      "2014-12-22\n",
      "2014-03-17\n",
      "2014-12-29\n",
      "2014-12-16\n",
      "2014-12-29\n",
      "2014-12-27\n",
      "2014-12-30\n",
      "2014-12-15\n",
      "2014-12-11\n",
      "2014-12-22\n",
      "error loading company page.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-e56f011bd6f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcompany_url\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks_top_50_large\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_company_reviews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompany_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mreviews_companies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreviews_companies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-158-70b9ec8c3228>\u001b[0m in \u001b[0;36mget_company_reviews\u001b[1;34m(driver, company_url)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtmlSource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# get all reviews from page and append to all_reviews list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mcurrent_reviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_reviews_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mall_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_reviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# if reviews are older than 2015 stop aggregating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-152-bfcb46f4fffc>\u001b[0m in \u001b[0;36mget_reviews_page\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_reviews_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'empReview'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcompany_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'employerName'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mreviews_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# add chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# initiate driver \n",
    "driver =  webdriver.Chrome(options=chrome_options) \n",
    "driver.get('https://www.glassdoor.com/index.htm') \n",
    "\n",
    "# NAVIGATE TO SIGN ON \n",
    "#page 1\n",
    "sign_in_button= driver.find_element(By.XPATH, '//button[text()=\"Sign In\"]')\n",
    "sign_in_button.click()\n",
    "\n",
    "# login page\n",
    "username = driver.find_element(By.ID,'modalUserEmail')\n",
    "username.send_keys('nicholasjang0614@gmail.com')\n",
    "password = driver.find_element(By.ID,'modalUserPassword')\n",
    "password.send_keys('ngtee0614')\n",
    "log_in_button = driver.find_element(By.NAME, 'submit')\n",
    "log_in_button.click()\n",
    "\n",
    "# time.sleep(1)\n",
    "# WAIT FOR MAIN PAGE TO LOAD AFTER LOGIN  \n",
    "try:\n",
    "    element = WebDriverWait(driver, 3).until(\n",
    "        EC.presence_of_element_located((By.ID, 'Discover'))\n",
    "    )\n",
    "except:\n",
    "    print('error loading main page.') \n",
    "\n",
    "reviews_companies = pd.DataFrame()\n",
    "\n",
    "for company_url in links_top_50_large[36:]:\n",
    "    time.sleep(5)\n",
    "    print(f'Getting reviews for {company_url}')\n",
    "    df = get_company_reviews(driver, company_url)\n",
    "    reviews_companies = pd.concat([reviews_companies, df])\n",
    "    \n",
    "reviews_companies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "For a single company\n",
    "Get all reviews by searching through all pages \n",
    "\"\"\"\n",
    "def get_company_reviews(driver, company_url):\n",
    "    try:\n",
    "        driver.get(company_url)\n",
    "    except Exception as e:\n",
    "        print('Unable to get new URL.')\n",
    "        print(e)\n",
    "\n",
    "    # WAIT FOR COMPANY PAGE TO LOAD  # time.sleep(2)\n",
    "    wait_for_page(driver)\n",
    "\n",
    "    # GET PAGE SOURCE \n",
    "    htmlSource = driver.page_source\n",
    "    soup = BeautifulSoup(htmlSource,\"html.parser\")\n",
    "\n",
    "    # GET NUMBER OF PAGES OF REVIEWS \n",
    "    num_pages = get_num_pages(soup)\n",
    "\n",
    "    # get reviews from first page \n",
    "    all_reviews = []\n",
    "    first_review = get_reviews_page(soup)\n",
    "    all_reviews.append(first_review)\n",
    "\n",
    "    # if more than one page\n",
    "    if num_pages > 1:\n",
    "        for i in range(2,num_pages+1,1): \n",
    "            # get the new url for another page \n",
    "            current_url = get_new_url(company_url, i) \n",
    "            \n",
    "            # open page and wait for loading \n",
    "            try:\n",
    "                driver.get(current_url)\n",
    "            except Exception as e:\n",
    "                print('Unable to get new URL.')\n",
    "                print(e)\n",
    "                \n",
    "            wait_for_page(driver)\n",
    "            # download the source of page \n",
    "            htmlSource = driver.page_source\n",
    "            soup = BeautifulSoup(htmlSource,\"html.parser\")\n",
    "            # get all reviews from page and append to all_reviews list \n",
    "            current_reviews = get_reviews_page(soup)\n",
    "            all_reviews.append(current_reviews)\n",
    "            # if reviews are older than 2015 stop aggregating \n",
    "            if get_date(soup, '2015') == False:\n",
    "                break\n",
    "    # save to csv\n",
    "    final_df = pd.DataFrame(flatten(all_reviews))\n",
    "    final_df.to_csv(f'{get_company_name(soup)}.csv')\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst):\n",
    "    return list(itertools.chain(*lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_page(driver):\n",
    "    # WAIT FOR COMPANY PAGE TO LOAD \n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'EIReviews'))\n",
    "        )\n",
    "    except:\n",
    "        print('error loading company page.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_url(company_url, page_num):\n",
    "    url_split = company_url.split('.')\n",
    "    url_split[2] = url_split[2] + '_P{}'.format(page_num)\n",
    "    new_url = '.'.join(url_split)\n",
    "    return new_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_pages(soup):\n",
    "    footer_string = soup.find(class_='paginationFooter').text\n",
    "    num_results = int(footer_string.split('of ')[1].split(' ')[0].replace(',','')) \n",
    "    num_pages = math.ceil(int(num_results/10))\n",
    "    return num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(soup, year):\n",
    "    reviews = soup.find_all(class_ ='empReview')\n",
    "    \n",
    "    for review in reviews:\n",
    "        author_info = review.find(class_='authorInfo').text.split(' - ')\n",
    "        date = pd.to_datetime(author_info[0]).date()\n",
    "        if date < pd.to_datetime(year):\n",
    "            print(date)\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_name(soup):\n",
    "    company_title = soup.find(class_='employerName').text\n",
    "    return company_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_page(soup):\n",
    "    reviews = soup.find_all(class_ ='empReview')\n",
    "    company_title = soup.find(class_='employerName').text\n",
    "    reviews_page = []\n",
    "\n",
    "    for review in reviews:\n",
    "        review_dict = {}\n",
    "        headline = review.find('h2').text\n",
    "        overall_rating = float(review.find(class_='ratingNumber mr-xsm').text)\n",
    "\n",
    "        author_info = review.find(class_='authorInfo').text.split(' - ')\n",
    "        date = pd.to_datetime(author_info[0]).date()\n",
    "        title = author_info[1].split('\\xa0')[0]\n",
    "\n",
    "        pros = review.find_all(class_='v2__EIReviewDetailsV2__fullWidth')[0].find_all('p')[1].text\n",
    "        cons = review.find_all(class_='v2__EIReviewDetailsV2__fullWidth')[1].find_all('p')[1].text\n",
    "\n",
    "        review_dict['company'] = company_title\n",
    "        review_dict['headline'] = headline\n",
    "        review_dict['date'] = date\n",
    "        review_dict['overall_rating'] = overall_rating\n",
    "        review_dict['author_position'] = title\n",
    "        review_dict['pros'] = pros\n",
    "        review_dict['cons'] = cons \n",
    "\n",
    "        reviews_page.append(review_dict)\n",
    "        \n",
    "    return reviews_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
